{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Zdlvhi4pQtd"
   },
   "source": [
    "This notebook is intended to show implementation of the metrics listed in the Task 0 of RecSys advanced course  ([course page](https://kb.epam.com/display/EPMCBDCCDS/RecSys+course))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c-NJDQGloyiW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "Data to get reference scores is generated with the following in mind:\n",
    "\n",
    "* Each row represents a single user\n",
    "* Column `prediction` represents predictions (list of items recommended)\n",
    "* Column `ground_truth` represents ground truth data (items that user really bought)\n",
    "\n",
    "Load the data from here - [link](https://kb.epam.com/download/attachments/789625167/recsys_task0_dataset.parquet?version=1&modificationDate=1625582742133&api=v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('recsys_task0_dataset.parquet')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df['ground_truth'].values # Array of ground truths for a user (array of arrays)\n",
    "y_pred = df['prediction'].values # Array of predictions for a user (array of arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skrGVN8zpIzF"
   },
   "source": [
    "# HitRate@k\n",
    "$y_{true}, y_{pred}$ – 2D arrays $(users, predictions)$ (or list of lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAZyBzbspKiN"
   },
   "outputs": [],
   "source": [
    "def hit_rate_at_k(y_true, y_pred, k=5):\n",
    "    return np.mean([\n",
    "        int(any(np.isin(y_pred[i][:k], y_true[i]))) \n",
    "        for i in range(y_true.shape[0])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HitRate@3: %.3f' % hit_rate_at_k(y_true, y_pred, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('HitRate@5: %.3f' % hit_rate_at_k(y_true, y_pred, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMozt9e6wlhq"
   },
   "source": [
    "# MAP@k\n",
    "For MAP@k: $y_{true}, y_{pred}$ – 2D arrays $(users,predictions)$ (or list of lists)\n",
    "\n",
    "For AP@k, Precision@k:  $y_{true}, y_{pred}$ – 1D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxfXofXrwuqE"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(y_true, y_pred, k=5):\n",
    "    intersection = set(y_pred[:k]) & set(y_true)\n",
    "    return len(intersection) / k\n",
    "\n",
    "\n",
    "def average_precision_at_k(y_true, y_pred, k=5):\n",
    "    hits = 0\n",
    "    s = 0\n",
    "    for i in range(len(y_pred[:k])):\n",
    "        if y_pred[i] in y_true:\n",
    "            hits += 1\n",
    "            s += hits / (i + 1)\n",
    "    if hits == 0:\n",
    "        return 0\n",
    "    return s / hits\n",
    "\n",
    "\n",
    "def map_at_k(y_true, y_pred, k=5):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return np.mean([\n",
    "        average_precision_at_k(y_true[i], y_pred[i], k=k)\n",
    "        for i in range(len(y_true))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAP@3: %.3f' % map_at_k(y_true, y_pred, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAP@5: %.3f' % map_at_k(y_true, y_pred, k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEjG-0ws1r0H"
   },
   "source": [
    "# NDCG@k\n",
    "For NDCG@k: $y_{true}, y_{pred}$ – 2D arrays $(users,predictions)$ (or list of lists)\n",
    "\n",
    "For ndcg@k:  $y_{true}, y_{pred}$ – 1D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRXxfwTe1q0l"
   },
   "outputs": [],
   "source": [
    "def ndcg_at_k(y_true, y_pred, k=5):\n",
    "    ideal_gain = sum([1 / np.log2(i + 2) for i in range(k)])\n",
    "    dcg = sum([\n",
    "        1 / np.log2(i + 2)\n",
    "        for i, rating in enumerate(y_pred[:k])\n",
    "        if rating in y_true\n",
    "    ])\n",
    "    return dcg / ideal_gain\n",
    "\n",
    "\n",
    "def NDCG_at_k(y_true, y_pred, k=5):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    return np.mean([\n",
    "        ndcg_at_k(y_true[i], y_pred[i], k=k)\n",
    "        for i in range(len(y_true))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NDCG@3: %.3f' % NDCG_at_k(y_true, y_pred, k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NDCG@5: %.3f' % NDCG_at_k(y_true, y_pred, k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EPAM.Task0.Implementation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
